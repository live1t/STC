{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46daf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This program calculates the mean population vector correlations between sessions across all mice\n",
    "#It also compares the mean population vector correlations to shuffled populatin vector correlations\n",
    "#The output is a comparison of the population vector correlations to a threshold value of the shuffled correlations (the 95% value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import math\n",
    "\n",
    "#To display all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_column', None)\n",
    "\n",
    "#this is the location of the csv files for the output\n",
    "out_path=r'/Users/your_output_path_here'\n",
    "newpath = out_path + r'/99%'\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df029870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define number of bins/gridcells\n",
    "Grid_dimension=16\n",
    "N_bins=Grid_dimension*Grid_dimension\n",
    "\n",
    "#define number of shuffles for the comparison\n",
    "No_shuffles=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a48fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = r'/Users/location_of_session_1_ratemaps' # use your path for session 1 ratemaps\n",
    "\n",
    "#concatenate files in a folder to get a csv of ratemaps of session 1 with all cells of interst from all mice\n",
    "all_files_1 = glob.glob(os.path.join(path_1, \"*.csv\"))\n",
    "\n",
    "#read in file and remove duplicate column\n",
    "df_1 = pd.concat((pd.read_csv(f) for f in all_files_1), axis=1, ignore_index=False)\n",
    "session_1=df_1.drop(['Unnamed: 0'], axis=1)\n",
    "session_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = r'/Users/location_of_session_2_ratemaps' # use your path for session 2 ratemaps\n",
    "\n",
    "#concatenate files in a folder to get a csv of ratemaps of session 2 with all cells of interst from all mice\n",
    "all_files_2 = glob.glob(os.path.join(path_2, \"*.csv\")) \n",
    "\n",
    "#read in file and remove duplicate column\n",
    "session_2 = pd.concat((pd.read_csv(f) for f in all_files_2), axis=1, ignore_index=False)\n",
    "session_2=session_2.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de213671",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_3 = r'/Users/location_of_session_3_ratemaps' # use your path for session 3 ratemaps\n",
    "\n",
    "#concatenate files in a folder to get a csv of ratemaps of session 3 with all cells of interst from all mice\n",
    "all_files_3 = glob.glob(os.path.join(path_3, \"*.csv\")) \n",
    "\n",
    "#read in file and remove duplicate column\n",
    "session_3 = pd.concat((pd.read_csv(f) for f in all_files_3), axis=1, ignore_index=False)\n",
    "session_3=session_3.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_4 = r'/Users//location_of_session_4_ratemaps' # use your path for session 4 ratemaps\n",
    "\n",
    "#concatenate files in a folder to get a csv of ratemaps of session 4 with all cells of interst from all mice\n",
    "all_files_4 = glob.glob(os.path.join(path_4, \"*.csv\")) #concatenate files in a folder\n",
    "\n",
    "#read in file and remove duplicate column\n",
    "session_4 = pd.concat((pd.read_csv(f) for f in all_files_4), axis=1, ignore_index=False)\n",
    "session_4=session_4.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaaf5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of pop vector correlation between session 1 and 3 across all cells\n",
    "pop_vector_correlation_1_3=session_1.corrwith(session_3, axis = 1)\n",
    "pop_vector_correlation_1_3_mean=pop_vector_correlation_1_3.mean()\n",
    "pop_vector_correlation_1_3_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d707636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of pop vector correlation between session 2 and 4 across all cells\n",
    "pop_vector_correlation_2_4=session_2.corrwith(session_4, axis = 1)\n",
    "pop_vector_correlation_2_4_mean=pop_vector_correlation_2_4.mean()\n",
    "pop_vector_correlation_2_4_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cba603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with results of population vector correlations\n",
    "pop_vector_correlation_means=[pop_vector_correlation_1_3_mean,pop_vector_correlation_2_4_mean]\n",
    "pop_vector_correlation_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part shuffles the data to determine values to beat for significance\n",
    "\n",
    "#set up arrays for shuffled correlation values\n",
    "pop_vector_correlation_1_3_mean_shuffled=np.zeros((No_shuffles))\n",
    "pop_vector_correlation_2_4_mean_shuffled=np.zeros((No_shuffles))\n",
    "\n",
    "for i in range (No_shuffles):\n",
    "    \n",
    "    #shuffle columns of dataframes and rename columns\n",
    "    shuffled_data_session_one=session_1.sample(frac=1, axis=1).reset_index(drop=True)\n",
    "    shuffled_data_session_one.columns = range(shuffled_data_session_one.columns.size)\n",
    "    \n",
    "    shuffled_data_session_two=session_2.sample(frac=1, axis=1).reset_index(drop=True)\n",
    "    shuffled_data_session_two.columns = range(shuffled_data_session_two.columns.size)\n",
    "    \n",
    "    shuffled_data_session_three=session_3.sample(frac=1, axis=1).reset_index(drop=True)\n",
    "    shuffled_data_session_three.columns = range(shuffled_data_session_three.columns.size)\n",
    "    \n",
    "    shuffled_data_session_four=session_4.sample(frac=1, axis=1).reset_index(drop=True)\n",
    "    shuffled_data_session_four.columns = range(shuffled_data_session_four.columns.size)\n",
    "    \n",
    "    #calculate correlations between shuffled population vectors\n",
    "    pop_vector_correlation_1_3_shuffled=shuffled_data_session_one.corrwith(shuffled_data_session_three, axis = 1)\n",
    "    pop_vector_correlation_2_4_shuffled=shuffled_data_session_two.corrwith(shuffled_data_session_four, axis = 1)\n",
    "    \n",
    "    #average correlations across all cells\n",
    "    shuffled_pop_vector_correlation_1_3_mean=pop_vector_correlation_1_3_shuffled.mean()\n",
    "    shuffled_pop_vector_correlation_2_4_mean=pop_vector_correlation_2_4_shuffled.mean()\n",
    "    \n",
    "    #write averages to arrays\n",
    "    pop_vector_correlation_1_3_mean_shuffled[i]=pop_vector_correlation_1_3_shuffled.mean()\n",
    "    pop_vector_correlation_2_4_mean_shuffled[i]=pop_vector_correlation_2_4_shuffled.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert arrays of shuffled correlation values to dataframes\n",
    "pv_1_3_mean_shuffled = pd.DataFrame(pop_vector_correlation_1_3_mean_shuffled)\n",
    "pv_2_4_mean_shuffled = pd.DataFrame(pop_vector_correlation_2_4_mean_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write shuffled correlation values to files for plotting\n",
    "pv_1_3_mean_shuffled.to_csv(f'{newpath}/PV_shuffles1_3.csv', index=True)\n",
    "pv_2_4_mean_shuffled.to_csv(f'{newpath}/PV_shuffles2_4.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59904e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistics for shuffled values using .describe\n",
    "des_pv_1_3_mean_shuffled = pv_1_3_mean_shuffled.describe()\n",
    "des_pv_2_4_mean_shuffled = pv_2_4_mean_shuffled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns of description dataframes\n",
    "des_pv_1_3_mean_shuffled = des_pv_1_3_mean_shuffled.rename(columns={0: '1-3'})\n",
    "des_pv_2_4_mean_shuffled = des_pv_2_4_mean_shuffled.rename(columns={0: '2-4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine statistics of shuffled values and write to file\n",
    "shuffle_description = pd.concat([des_pv_1_3_mean_shuffled, des_pv_2_4_mean_shuffled], axis=1)\n",
    "\n",
    "shuffle_description\n",
    "shuffle_description.to_csv(f'{newpath}/PVshuffle_description_99%.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort shuffled population vector correlations in value order\n",
    "pop_vector_correlation_1_3_mean_shuffled=np.sort(pop_vector_correlation_1_3_mean_shuffled)\n",
    "pop_vector_correlation_2_4_mean_shuffled=np.sort(pop_vector_correlation_2_4_mean_shuffled)\n",
    "\n",
    "#determine number to beat (i.e., the shuffled vale the true vaue has to beat to be better than 95% of shuffles)\n",
    "beat_index=(99*No_shuffles)//100 #index of top 1% value\n",
    "pop_vector_correlation_means_to_beat=[pop_vector_correlation_1_3_mean_shuffled[beat_index],\n",
    "                                     pop_vector_correlation_2_4_mean_shuffled[beat_index]]\n",
    "\n",
    "pop_vector_correlation_means_to_beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19791fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create output dataframe of real correlation values and shuffled correlation values\n",
    "\n",
    "PV = pd.DataFrame([pop_vector_correlation_means, pop_vector_correlation_means_to_beat], \n",
    "                  columns=[\"1-3\", \"2-4\"], \n",
    "                  index=[\"Correlation mean\", \"Shuffled correlation mean\"])\n",
    "PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a7d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write PV to file \n",
    "PV.to_csv(f'{newpath}/PV.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55d22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0259870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
